{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcd8Y6mXaNMEw5xoZIwCtL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjalidabare/Spaceship_Titanic_KaggleCompetition/blob/main/Spaceship_Titanic_Kaggle_Competition_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes\n",
        "\n",
        "*   Data Set is Balanced for target variable\n",
        "*   Many variables have missing values\n",
        "*   'Passenger_ID' is an identification variable. Hence pre-processing is not needed.\n",
        "*   'Name' should be dropped due to high cardinality\n",
        "*   'Cabin' variable should be splitted before use.\n",
        "*   Target Variable is Binary. Hence Binary Classification models should be used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8JScObZZffNz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBMtD9kzVAX-"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "ImsVh97kWphj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "nRUUzZfnWvMW"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "PoVkDI1PW2Ke"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!kaggle competitions download -c spaceship-titanic"
      ],
      "metadata": {
        "id": "YG_u6pqsW9kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip spaceship_titanic.zip"
      ],
      "metadata": {
        "id": "ZMv-pSgrXEbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip"
      ],
      "metadata": {
        "id": "xhOkp689Yb0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas_profiling import ProfileReport"
      ],
      "metadata": {
        "id": "iI2YBW_KZhpH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "Eunuhg4SZw2S"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "1kYvBAbTZ4Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile = ProfileReport(df, title='Spaceship Titanic')"
      ],
      "metadata": {
        "id": "A79YmNegZ5c8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile.to_notebook_iframe()"
      ],
      "metadata": {
        "id": "3pNIBnH1aZJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "UnNgb-zrmZQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split fucntion for cabin variable\n",
        "def split_function(x):\n",
        "  if len(str(x).split('/'))<3:\n",
        "    return [\"Missing\",\"Missing\",\"Missing\"]\n",
        "  else:\n",
        "    return str(x).split('/')\n"
      ],
      "metadata": {
        "id": "XngZNzRXcyOD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pre-processing function\n",
        "def pre_processing(df):\n",
        "  #fill missing values of Homeplanet with'missing'\n",
        "  df['HomePlanet'].fillna('Missing',inplace=True)\n",
        "  #fill missing values of Cryosleep with 'missing'\n",
        "  df['CryoSleep'].fillna('Missing',inplace=True)\n",
        "  #split the cabin variable and create a Tempcabin variable\n",
        "  df['Tempcabin']=df['Cabin'].apply(split_function)\n",
        "  #create a new column for cabin Deck\n",
        "  df['Deck']=df['Tempcabin'].apply(lambda x: x[0])\n",
        "  #create a new column for cabin side\n",
        "  df['Side']=df['Tempcabin'].apply(lambda x: x[2])\n",
        "  #dropping Tempcabin variable\n",
        "  df.drop('Tempcabin',axis=1,inplace=True)\n",
        "  #dropping Cabin variable\n",
        "  df.drop('Cabin',axis=1,inplace=True)\n",
        "  #fill missing values of Deastination with'missing'\n",
        "  df['Destination'].fillna('Missing',inplace=True)\n",
        "  #fill missing values of Age with'mean'\n",
        "  df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
        "  #fill missing values of VIP with'missing'\n",
        "  df['VIP'].fillna('Missing',inplace=True)\n",
        "  #fill missing values of monetory variables with 0\n",
        "  df['RoomService'].fillna(0,inplace=True)\n",
        "  df['FoodCourt'].fillna(0,inplace=True)\n",
        "  df['ShoppingMall'].fillna(0,inplace=True)\n",
        "  df['Spa'].fillna(0,inplace=True)\n",
        "  df['VRDeck'].fillna(0,inplace=True)\n",
        "  #dropping Name variable\n",
        "  df.drop('Name',axis=1,inplace=True)\n"
      ],
      "metadata": {
        "id": "5PuzrqtwlRIj"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating analytical base table\n",
        "abt=df.copy()"
      ],
      "metadata": {
        "id": "S8NpmecJsxI0"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_processing(abt)"
      ],
      "metadata": {
        "id": "8J_spwoYs3EL"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abt.info()"
      ],
      "metadata": {
        "id": "Tj4D3vDut25W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0gybMOhvsT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelling\n",
        "\n",
        "*   Create Feature and Target variables\n",
        "*   train test split\n",
        "*   one hot encoding for categorical variables\n",
        "*   create model pipleines  \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xisN5pthyc_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "hMfLnhor0IBc"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Variable\n",
        "X=abt.drop(['Transported','PassengerId'],axis=1)\n",
        "#onehotecoding\n",
        "X=pd.get_dummies(X)\n",
        "#Target Variable\n",
        "y=abt['Transported']"
      ],
      "metadata": {
        "id": "pHqHJURf2e7T"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=123)"
      ],
      "metadata": {
        "id": "yd46-aZk2-qC"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "3QfiGU9a5ozN"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setup ML Pipeline\n",
        "\n",
        "pipelines= {\n",
        "    'lr':make_pipeline(StandardScaler(), LogisticRegression(random_state=123)),\n",
        "    'kn':make_pipeline(StandardScaler(), KNeighborsClassifier()),\n",
        "    'svm':make_pipeline(StandardScaler(), LinearSVC(random_state=123)),\n",
        "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier(random_state=123)),\n",
        "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=123)),\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "2uBPdmtK3cY-"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create grid\n",
        "\n",
        "grid={\n",
        "    'lr':{\n",
        "        'logisticregression__C':[0.5,0.1,0.15] ,'logisticregression__max_iter':[50,100,150,200]\n",
        "    },\n",
        "    'kn':{\n",
        "        'kneighborsclassifier__n_neighbors':[5,10,15],'kneighborsclassifier__n_jobs':[-1]\n",
        "    },\n",
        "    'svm':{\n",
        "        'linearsvc__C':[1.0,1.5,2.0],'linearsvc__max_iter':[1000,2000,3000,4000,5000]\n",
        "    },\n",
        "    'rf':{\n",
        "        'randomforestclassifier__n_estimators':[100,200,300],'randomforestclassifier__n_jobs':[-1]\n",
        "    },\n",
        "    'gb':{\n",
        "        'gradientboostingclassifier__n_estimators':[100,200,300]\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "UJSVeRin4NMn"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitted_models={}\n",
        "#loop through all the algos\n",
        "for algo,pipeline in pipelines.items():\n",
        "  #create new gridsearch cv class\n",
        "  model=GridSearchCV(pipeline,grid[algo],n_jobs=-1,cv=10)\n",
        "  #train the models for selected parameters\n",
        "  model.fit(X_train,y_train)\n",
        "  #store the model in the dictionary\n",
        "  fitted_models[algo]=model"
      ],
      "metadata": {
        "id": "x2w7EbuP8D_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Evaluation"
      ],
      "metadata": {
        "id": "rqsRd4IbKymQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "0wPmXI_8-R7C"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test the accuracy of each model fitted\n",
        "for algo,model in fitted_models.items():\n",
        "  yhat=model.predict(X_test)\n",
        "  accuracy=accuracy_score(y_test,yhat)\n",
        "  precision=precision_score(y_test,yhat)\n",
        "  recall=recall_score(y_test,yhat)\n",
        "  print(f'Metric for {algo}: accuracy- {accuracy}, precision- {precision}, recall- {recall}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmTc0mGGLTf1",
        "outputId": "65f1af4a-db4c-43f3-9655-f2cb5d4fe9d9"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric for lr: accuracy- 0.8056354226566993, precision- 0.7956989247311828, recall- 0.8333333333333334\n",
            "Metric for kn: accuracy- 0.7768832662449684, precision- 0.8246753246753247, recall- 0.7150900900900901\n",
            "Metric for svm: accuracy- 0.8062104657849338, precision- 0.8017524644030668, recall- 0.8243243243243243\n",
            "Metric for rf: accuracy- 0.80448533640023, precision- 0.8246445497630331, recall- 0.7837837837837838\n",
            "Metric for gb: accuracy- 0.816561242093157, precision- 0.7979057591623037, recall- 0.8581081081081081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving the Model"
      ],
      "metadata": {
        "id": "R1iajZfSNoxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "uM0UPmr0NqvT"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gradientboosted.pkl','wb')as f:\n",
        "  pickle.dump(fitted_models['gb'],f)"
      ],
      "metadata": {
        "id": "e8odjxu-N1Sv"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reload the saved model\n",
        "with open('gradientboosted.pkl','rb')as f:\n",
        "  reloaded_model=pickle.load(f)"
      ],
      "metadata": {
        "id": "vK4rF6OROr_n"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reloaded_model"
      ],
      "metadata": {
        "id": "kV85V363O-4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l8BFGqDhPC4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predicition on Test Data\n",
        "\n",
        "*  test data set does not have the target variable\n",
        "*  so the prediction should be done on feature variables after following through the pre-processing and one hot encoding\n"
      ],
      "metadata": {
        "id": "fhppUHJaPVV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df=pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "JRkHcaszPXXn"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abt_test=test_df.copy()"
      ],
      "metadata": {
        "id": "7y3Vke3gPnI_"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess test data\n",
        "pre_processing(abt_test)"
      ],
      "metadata": {
        "id": "8VMWNLvpPqUX"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#onehot encoding on test data\n",
        "abt_test_final=pd.get_dummies(abt_test.drop('PassengerId',axis=1))\n"
      ],
      "metadata": {
        "id": "hpj0sLW_P-lB"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_test=fitted_models['gb'].predict(abt_test_final)"
      ],
      "metadata": {
        "id": "TXd3OgrxQcOK"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['PassengerId']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0L0iwcVSzIG",
        "outputId": "0e89bec9-1ac3-4e8d-c51f-364e2af3639a"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0013_01\n",
              "1       0018_01\n",
              "2       0019_01\n",
              "3       0021_01\n",
              "4       0023_01\n",
              "         ...   \n",
              "4272    9266_02\n",
              "4273    9269_01\n",
              "4274    9271_01\n",
              "4275    9273_01\n",
              "4276    9277_01\n",
              "Name: PassengerId, Length: 4277, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df=pd.DataFrame([test_df['PassengerId'],yhat_test]).T"
      ],
      "metadata": {
        "id": "cPdnwrUaR1W7"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df.columns=['PassengerId','Transported']"
      ],
      "metadata": {
        "id": "DVDev3VUSlt6"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Submit to Kaggle"
      ],
      "metadata": {
        "id": "4fHjuZYJTa4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df.to_csv('kaggle_submission.csv',index=False)"
      ],
      "metadata": {
        "id": "P-uRvVEaTSgQ"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c spaceship-titanic -m \"Initial Model\" -f \"kaggle_submission.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ8yDEhLTlQE",
        "outputId": "814f19be-304e-4ce9-a5c6-f2d764b20f57"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 56.2k/56.2k [00:03<00:00, 18.0kB/s]\n",
            "Successfully submitted to Spaceship Titanic"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pkmO-5A-UI7l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}